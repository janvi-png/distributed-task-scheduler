# Distributed Task Scheduler

A fault-tolerant background job processing system built with FastAPI, SQLAlchemy, and worker processes.

This project demonstrates how production systems:

manage asynchronous workloads

persist state in SQL databases

recover from worker crashes

retry failed jobs safely

expose monitoring endpoints

#ğŸ§  Architecture Overview

The system is composed of two main services:

1. API Server

2. Accepts job submissions via REST

3. Persists jobs in a SQL database

4. Exposes /stats endpoint for monitoring

5. Worker Process(es)

6. Poll the database for pending jobs

7. Atomically claim jobs

8. Execute tasks
9.  Retry failures
10.   Mark jobs DONE or FAILED

  # ğŸ—ï¸ High-Level Flow
  
Client
   |
   v
FastAPI Server  --->  SQL Database (jobs table)
                           ^
                           |
                    Worker Processes

ğŸ§© Components
distributed-task-scheduler/
â”œâ”€â”€ api/              # REST API service
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ worker/           # Background workers
â”‚   â””â”€â”€ worker.py
â”œâ”€â”€ db/               # Database models + engine
â”‚   â”œâ”€â”€ database.py
â”‚   â””â”€â”€ models.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ README.md

âš™ï¸ Tech Stack

Python 3.10+

FastAPI

SQLAlchemy

SQLite (local) / PostgreSQL (prod)

Uvicorn

REST APIs

â–¶ï¸ How To Run Locally
1ï¸âƒ£ Clone repo
git clone https://github.com/<your-username>/distributed-task-scheduler.git
cd distributed-task-scheduler

2ï¸âƒ£ Create virtual env
python -m venv venv


Activate:

Windows

venv\Scripts\activate


Linux / Mac

source venv/bin/activate

3ï¸âƒ£ Install deps
pip install -r requirements.txt

4ï¸âƒ£ Run API server
python -m uvicorn api.main:app --reload


Swagger UI:

http://127.0.0.1:8000/docs

5ï¸âƒ£ Run worker

In another terminal:

python -m worker.worker

6ï¸âƒ£ Submit jobs

Using curl:

curl -X POST "http://127.0.0.1:8000/jobs?task_type=test&payload=hello"


Or via Swagger UI.

7ï¸âƒ£ Monitor
curl http://127.0.0.1:8000/stats

ğŸ’¥ Failure Handling

This system intentionally simulates failures to test reliability.

Workers fail the first attempt

Jobs are re-queued

Retries capped at MAX_ATTEMPTS

After limit â†’ marked FAILED

This validates:

âœ” idempotent processing
âœ” retry safety
âœ” crash recovery
âœ” persistent job state

ğŸ“Š What This Project Demonstrates

This project showcases real backend engineering fundamentals:

distributed worker architecture

SQL-backed queues

concurrency handling

transactional job claiming

retry logic

fault tolerance

RESTful service design

observability via stats endpoint

ğŸš€ Resume-Ready Description

Built a fault-tolerant background job scheduler with FastAPI and SQL, supporting concurrent workers, automatic retries, and crash recovery. Designed persistent job state tracking and monitoring endpoints to analyze system throughput and failures.



Both services operate independently and can scale horizontally.
